<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="Spreading Creative Commons in New Zealand">
<meta name="author" content="CCANZ">
<title>CCANZ (old posts, page 19) | CCANZ</title>
<link href="assets/css/all.css" rel="stylesheet" type="text/css">
<!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js" type="text/javascript"></script>
    <![endif]--><link rel="alternate" type="application/rss+xml" title="RSS" href="rss.xml">
</head>
<body>
    <div id="wrp">
        <div id="cont">
            <div id="page">
                <header><h1>
                        <a href="http://wcmckee.com/ccanz/" title="CCANZ" rel="home">CCANZ</a>
                    </h1>
                </header><div id="body">
                    <nav><ul>
<li><a href="http://wcmckee.com/ccanz/" title="Home" rel="home">Home</a></li>
                            <li><a href="http://wcmckee.com/ccanz/categories/" title="Categories">Categories</a></li>
			    <li><a href="http://wcmckee.com/ccanz/archive.html" title="Archive">Archive</a></li>
			    <li><a href="http://wcmckee.com/ccanz/stories/about-2/about-creative-commons.html" title="About">About</a></li> 
                            <li><a href="http://wcmckee.com/ccanz/rss.xml" title="RSS feed">RSS</a></li>
                            <li><a href="https://github.com/wcmckee/ccanz-static" title="Site source">Site Source</a></li>
		            <li><a href="https://twitter.com/CC_Aotearoa">Twitter</a></li>
			    <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">
		            <img alt="Creative Commons License BY" style="border-width:0; margin-bottom:12px;" src="https://upload.wikimedia.org/wikipedia/commons/1/16/CC-BY_icon.svg"></a>
			    <li>Except where otherwise noted, copyright content on this site is licensed under a Creative Commons Attribution 4.0 International Licence.</li>
                        </ul></nav><div id="content">
        <article class="teaser h-entry post-text"><h1 class="p-name">
<a href="posts/2013/10/25/review-is-the-key-to-open-access.html" class="u-url">Review Is the Key to Open Access</a>
             <time class="published dt-published" datetime="2013-10-25T14:26:39+13:00">2013-10-25 14:26</time>
</h1>
        <div class="e-content">
        <div>
<p></p>
<h5>By Andrew Preston, co-founder of <a href="https://publons.com/" target="_blank">Publons</a>
</h5>
<p>A favourite ploy among unsolicited email advertising, that bane of the connected world, is the offer of instant degrees conferred by bogus institutions. Easy to get, sure, but unlikely to get you far in a competitive job market. In short, where you got your degree matters. Reputation is everything.</p>
<p>It’s the same in the world of academic publishing. Peer-review serves an essential role as the gatekeeper to research. Scientists evaluate the work of their peers to make sure the work is sound. Where you get your paper published matters too. This second layer of evaluation – and reputation – is added by the exclusivity (and impact factor) of the publication itself. The system is designed to give academics greater confidence in the published literature they choose to read.</p>
<p>[quote float="right"]The traditional approach serves to limit discussion and debate[/quote]</p>
<p>It’s a system that has continued more or less unchanged and unchallenged for centuries. While, in the last few years, the internet has transformed virtually every publishing industry, there has been little experiment or innovation in the way academic research is communicated and evaluated.</p>
<p>The open access movement has challenged the traditional academic journal model on a single front: publication. While open access has made it easier for people to access a wider range of material, the issue of evaluation remains. In this critical area, traditional journals still hold all the cards.</p>
<p>This issue was highlighted by John Bohannon’s recent <a href="http://www.sciencemag.org/content/342/6154/60" target="_blank">open access journal sting</a>. Bohannon submitted versions of a fake paper to 304 open access journals. This paper was so flawed that no journal should have accepted it, and yet more than half did!</p>
<p>It’s tempting to blame the open access model for this, but that’s not the problem. We need to focus on the evaluation process -- the peer-review. Reviewing is a necessary but thankless task. Reviewers get no credit for their time and effort. Journals struggle to find qualified reviewers who don’t have conflicts of interest. As a result, the review process can take months, slowing down the dissemination of research it is designed to facilitate. And, as Bohannon showed, that’s only if it’s done well.</p>
<p>The traditional approach serves to limit discussion and debate. There is no inherent reason that only one or two experts in a field should determine the validity of a paper, nor that their evaluations be kept secret. There is plenty of valuable knowledge out there in the heads of experts. We just need to figure out how to get it on the web, because if we succeed at that we strengthen the case for open access.</p>
<p>This starts with giving reviewers credit for their work. There are many ways to do this. One approach is to turn review into a publication itself. We’ve recently <a href="http://blog.publons.com/post/61380784056/announcing-doi-support-for-reviews" target="_blank">begun allocating</a> Digital Object Identifiers (DOI) to reviews performed on Publons.com, making them citable contributions to the scientific literature. While DOIs are standard for published articles and datasets, the application of DOIs to peer review is a world first. Effectively, this puts reviews on the same footing as publications. For academics, it means they can augment their publication record with a portfolio of reviews. This record can be used to strengthen applications for funding and jobs, and to collaborate in the academic community on a deeper level.</p>
<p>We’re not the only ones working to open up peer review. A number of interesting startups have begun to work in this space. PeerJ, PubPeer, Libre, F1000, Axios Review, PeerEvaluation, Rubriq, The Winnower, and Peerage of Science have all announced initiatives focused on improving review. These range from new publishing models, to post-publication review platforms, to peer-review as a service.</p>
<p>For an open access world to succeed we need our gatekeepers. We need to make sure they get ‘paid’. Giving peer reviewers recognition and credit for their indispensable contributions to science provides a greater incentive for them to contribute high-quality, timely reviews. The payoff for everyone is better debate, greater transparency and the enhanced reputation of open access material, leading ultimately to faster and better communication of science.</p>
<p>[Andrew received his PhD in condensed matter physics from Victoria University of Wellington in 2010, and then did a postdoc focused on x-ray spectroscopy at Boston University. His firsthand experiences writing and reviewing papers led him to found Publons. This piece is made available under <a href="http://creativecommons.org/licenses/by-sa/3.0/nz/" target="_blank">Creative Commons Attribution Share-Alike 3.0 New Zealand licence</a>.]</p>
</div>
        </div>
                        <a href="posts/2013/10/25/review-is-the-key-to-open-access.html#disqus_thread" data-disqus-identifier="cache/posts/2013/10/25/review-is-the-key-to-open-access.html">Comments</a>


        </article><article class="teaser h-entry post-text"><h1 class="p-name">
<a href="posts/review-key-open-access.html" class="u-url">Review is the Key to Open Access</a>
             <time class="published dt-published" datetime="2013-10-25T00:30:34+13:00">2013-10-25 00:30</time>
</h1>
        <div class="e-content">
        <div>
<p></p>
<h5>By Andrew Preston, co-founder of <a href="https://publons.com/" target="_blank">Publons</a>
</h5>
<p>A favourite ploy among unsolicited email advertising, that bane of the connected world, is the offer of instant degrees conferred by bogus institutions. Easy to get, sure, but unlikely to get you far in a competitive job market. In short, where you got your degree matters. Reputation is everything.</p>
<p>It’s the same in the world of academic publishing. Peer-review serves an essential role as the gatekeeper to research. Scientists evaluate the work of their peers to make sure the work is sound. Where you get your paper published matters too. This second layer of evaluation – and reputation – is added by the exclusivity (and impact factor) of the publication itself. The system is designed to give academics greater confidence in the published literature they choose to read.</p>
<p>It’s a system that has continued more or less unchanged and unchallenged for centuries. While, in the last few years, the internet has transformed virtually every publishing industry, there has been little experiment or innovation in the way academic research is communicated and evaluated.</p>
<p>The open access movement has challenged the traditional academic journal model on a single front: publication. While open access has made it easier for people to access a wider range of material, the issue of evaluation remains. In this critical area, traditional journals still hold all the cards.</p>
<p>This issue was highlighted by John Bohannon’s recent <a href="http://www.sciencemag.org/content/342/6154/60" target="_blank">open access journal sting</a>. Bohannon submitted versions of a fake paper to 304 open access journals. This paper was so flawed that no journal should have accepted it, and yet more than half did!</p>
<p>It’s tempting to blame the open access model for this, but that’s not the problem. We need to focus on the evaluation process -- the peer-review. Reviewing is a necessary but thankless task. Reviewers get no credit for their time and effort. Journals struggle to find qualified reviewers who don’t have conflicts of interest. As a result, the review process can take months, slowing down the dissemination of research it is designed to facilitate. And, as Bohannon showed, that’s only if it’s done well.</p>
<p>The traditional approach serves to limit discussion and debate. There is no inherent reason that only one or two experts in a field should determine the validity of a paper, nor that their evaluations be kept secret. There is plenty of valuable knowledge out there in the heads of experts. We just need to figure out how to get it on the web, because if we succeed at that we strengthen the case for open access.</p>
<p>This starts with giving reviewers credit for their work. There are many ways to do this. One approach is to turn review into a publication itself. We’ve recently <a href="http://blog.publons.com/post/61380784056/announcing-doi-support-for-reviews" target="_blank">begun allocating</a> Digital Object Identifiers (DOI) to reviews performed on Publons.com, making them citable contributions to the scientific literature. While DOIs are standard for published articles and datasets, the application of DOIs to peer review is a world first. Effectively, this puts reviews on the same footing as publications. For academics, it means they can augment their publication record with a portfolio of reviews. This record can be used to strengthen applications for funding and jobs, and to collaborate in the academic community on a deeper level.</p>
<p>We’re not the only ones working to open up peer review. A number of interesting startups have begun to work in this space. PeerJ, PubPeer, Libre, F1000, Axios Review, PeerEvaluation, Rubriq, The Winnower, and Peerage of Science have all announced initiatives focused on improving review. These range from new publishing models, to post-publication review platforms, to peer-review as a service.</p>
<p>For an open access world to succeed we need our gatekeepers. We need to make sure they get ‘paid’. Giving peer reviewers recognition and credit for their indispensable contributions to science provides a greater incentive for them to contribute high-quality, timely reviews. The payoff for everyone is better debate, greater transparency and the enhanced reputation of open access material, leading ultimately to faster and better communication of science.</p>
<p>[Andrew received his PhD in condensed matter physics from Victoria University of Wellington in 2010, and then did a postdoc focused on x-ray spectroscopy at Boston University. His firsthand experiences writing and reviewing papers led him to found Publons. This piece is made available under <a href="http://creativecommons.org/licenses/by-sa/3.0/nz/" target="_blank">Creative Commons Attribution Share-Alike 3.0 New Zealand licence</a>.]</p>
</div>
        </div>
                        <a href="posts/review-key-open-access.html#disqus_thread" data-disqus-identifier="cache/posts/review-key-open-access.html">Comments</a>


        </article><article class="teaser h-entry post-text"><h1 class="p-name">
<a href="posts/2013/10/24/the-need-for-libre-open-access.html" class="u-url">The Need for Libre Open Access</a>
             <time class="published dt-published" datetime="2013-10-24T15:49:40+13:00">2013-10-24 15:49</time>
</h1>
        <div class="e-content">
        <div>
<p></p>
<h5>By Fabiana Kubke, Senior Lecturer, School of Medical Sciences, at the<a href="http://www.fmhs.auckland.ac.nz/sms/staffct/staff_details.aspx?staffID=6D6B7562303033" target="_blank"> University of Auckland</a> and Chair of the <a href="http://creativecommons.org.nz/about/who-we-are/" target="_blank">Creative Commons Aotearoa New Zealand Advisory Panel</a>.</h5>
<h5 id="docs-internal-guid-4535c1a2-e702-23d8-9e0c-b9896879e046"><strong>re·pos·i·to·ry</strong></h5>

<dl>
<dt><p dir="ltr">noun ri-ˈpä-zə-ˌtȯr-ē</p></dt>
<dd>
<p>a place where a large amount of something is stored</p>
</dd>
<dd>
<p>a person who possesses a lot of information, wisdom, etc. [1]</p>
</dd>
</dl>
<p dir="ltr">At University repositories, this “something” is the knowledge we generate as a result of our academic research. My institution (University of Auckland), like other academic institutions around the country, has an “Institutional Repository”. It is called “<a href="https://researchspace.auckland.ac.nz/">Research Space</a>” and I suspect many of my colleagues might have never heard of it, and many might not know how to make use of it.</p>

<p><a href="http://creativecommons.org.nz/wp-content/uploads/2013/10/Archives.jpg"><img class=" wp-image-4772   " alt="Archives New Zealand Lower Level Three Stacks by David Sanderson, via Flickr. Made available under a Creative Commons Attribution 2.0 Unported licence. " src="http://creativecommons.org.nz/wp-content/uploads/2013/10/Archives.jpg" width="256" height="384"></a> <a href="http://www.flickr.com/photos/archivesnz/8759939806/" target="_blank">"Archives New Zealand Lower Level Three Stacks"</a> by David Sanderson, via Flickr. Made available under a <a href="http://creativecommons.org/licenses/by/2.0/deed.en" target="_blank">Creative Commons Attribution 2.0 Unported licence.</a></p>
<p dir="ltr">Open Access is <a href="http://en.wikipedia.org/wiki/Open_access" target="_blank">usually described</a> as Gold (where the article is made accessible free of charge by the published) or Green (where some version of the manuscript, usually the peer reviewed version, is deposited by the author). I don’t personally find this distinction palatable, because the gold/green definition says more about mechanisms of delivery and less about liberties for reuse.</p>

<p dir="ltr">Those who know me also know that I prefer to think about Free Open Access (where the article is provided free of charge) and Libre Open Access (where the article is provided free of charge and there are few restrictions for reuse and repurposing). The copyright agreements we enter or the licence we choose when publishing open access defines where in the free-libre spectrum the article will sit.</p>

<p dir="ltr">If we wish to communicate our findings as widely as possible, shouldn’t we be opting for libre Open Access, where they can be reused, redistributed and repurposed? This week Daniel Mietchen, Raphael Wimmer and Nils Dagssonwas  <a href="http://blogs.plos.org/mindthebrain/2013/10/01/asap-awards-interview-with-daniel-mietchen/">received an award </a>for the work they did taking multimedia files that were part of libre Open Access literature and giving them a new life in WikiMedia, where they can be used to illustrate Wikipedia articles,  used for educational purposes, etc.</p>

<p dir="ltr">Unfortunately, research publications do not solely serve the purpose of communicating our findings. They are also perhaps the most important contribution through which our worth as academics will be measured when we apply for a job, apply for promotion or seek to be granted tenure. We may be forgiven a lot by staffing committees, but never a poor publication record. We have been taught that how we brand our publications (where we publish them) will be a major factor for that assessment.</p>

<p dir="ltr">It is not surprising then, that most of us will feel the need to do our best to place our article in the better branded journals, many of which will charge hefty Open Access fees, but will publish our article sometimes at a lower price or free of charge  if we are willing to give our rights as authors away to them.  Because this decision of where to publish is so intricately tied to career progress, the cultural inertia is hard to overcome.</p>

<p dir="ltr">[quote float="left"]For our outputs to have impact, they first need to be read.[/quote]</p>

<p dir="ltr">These days, it is rare that I will find someone who doesn’t think that Open Access is “a good thing”  (progress!). As soon as the term “Open Access” enters the discussion, however, I can see the $ shaped tears rolling down someone’s cheeks. Most frequently the discussion veers towards a standard list of “buts”.</p>

<p dir="ltr">Many of these “buts” are myths that seem to persist even in the face of evidence against them.  Once they have the mindset that Open Access is not a “viable” alternative to be embraced by them, their immediate community of practice or even their institution, it does not  seem to matter how much data is presented -- the response will inevitably be “Oh, ok. [pause] but…”  If we cannot change scientists’ minds when confronting them with evidence, how will we be able to persuade our agencies and institutions? Until we overcome our apprehensions about open access, should we just stick to the status quo?</p>

<p dir="ltr">Institutional repositories provide a place where authors that choose to publish in the traditional way can deposit the peer-reviewed accepted article for anyone to access free of charge. All authors need to do is to contact their librarian and they will happily show them how to do this. In New Zealand, articles that are deposited in these repositories are given a second life, free of pay-walls and indexed by Google. In New Zealand the articles (and other research artifacts) are aggregated  in <a href="http://nzresearch.org.nz/">http://nzresearch.org.nz/</a>.</p>

<p dir="ltr">[quote float="right"]Articles that are deposited in repositories are given a second life, free of pay-walls and indexed by Google.[/quote]</p>

<p dir="ltr">There are several types of artifact types listed in nzreasearch (theses, conference posters, journal articles, patents, datasets, etc) and the site provides a really nice user interface to search for material. I could find at the time of writing 20,450 thesis listed, 15,132 research articles  and 235 conference posters, for example. I doubt that these numbers (other than theses, perhaps) reflect the actual number of outputs from the NZ research sector. These numbers may instead indicate that more work needs to be done to encourage authors to make the deposition of their outputs in the repository a regular part of their workflow. I can’t help wondering whether, if we were asked to identify at our annual performance review, continuation, or promotions the proportion of our output that was deposited, we might see some progress.</p>

<p dir="ltr">My personal position is that research outputs that result from public funds should be made available under a copyright licence that minimises the restrictions on distribution and re-use. I also understand that authors may base their choice over where they publish on different kinds of reasons (some which I understand and other which I don’t). But even when authors choose to publish under traditional pay-walled schemes, the value of depositing in the institutional repository far outweigh the reasons not to do so.</p>

<p dir="ltr">This year’s Open Access Week focus is on “impact”, and for our outputs to have impact they first need to be read. <a href="https://twitter.com/brembs">Björn</a> Brems put it best when <a href="http://twitter.com/brembs/status/354486926562181120">he said</a>:</p>

<p dir="ltr">"No matter what field (or planet): limiting potential readership does not increase actual readership.”</p>

<p dir="ltr"> [1] Definition from <a href="http://www.merriam-webster.com/dictionary/repository">Merriam Webster</a> online dictionary</p>

<p dir="ltr">[You can read more from Fabiana at her blog, <a href="http://sciblogs.co.nz/building-blogs-of-science/" target="_blank">Building Blogs of Science</a>, part of the <a href="http://sciblogs.co.nz/bloggers/" target="_blank">Science Media Centre’s SciBlogs network</a>. She also blogs for the <a href="http://blogs.plos.org/mindthebrain/" target="_blank">Public Library of Science</a>.]</p>

<p></p>
</div>
        </div>
                        <a href="posts/2013/10/24/the-need-for-libre-open-access.html#disqus_thread" data-disqus-identifier="cache/posts/2013/10/24/the-need-for-libre-open-access.html">Comments</a>


        </article><article class="teaser h-entry post-text"><h1 class="p-name">
<a href="posts/need-libre-open-access.html" class="u-url">The Need for Libre Open Access</a>
             <time class="published dt-published" datetime="2013-10-24T00:32:32+13:00">2013-10-24 00:32</time>
</h1>
        <div class="e-content">
        <div>
<p></p>
<strong>By Fabiana Kubke</strong>
<p>Senior Lecturer, School of Medical Sciences, at the<a href="http://www.fmhs.auckland.ac.nz/sms/staffct/staff_details.aspx?staffID=6D6B7562303033" target="_blank"> University of Auckland</a> and Chair of the <a href="http://creativecommons.org.nz/about/who-we-are/" target="_blank">Creative Commons Aotearoa New Zealand Advisory Panel</a>.</p>
<h5 id="docs-internal-guid-4535c1a2-e702-23d8-9e0c-b9896879e046" dir="ltr"><strong>re·pos·i·to·ry</strong></h5>

<dl>
<dt><p dir="ltr">noun \ri-ˈpä-zə-ˌtȯr-ē\</p></dt>
<dd>
<p>a place where a large amount of something is stored</p>
</dd>
<dd>
<p>a person who possesses a lot of information, wisdom, etc. [1]</p>
</dd>
</dl>
<p dir="ltr">At University repositories, this “something” is the knowledge we generate as a result of our academic research. My institution (University of Auckland), like other academic institutions around the country, has an “Institutional Repository”. It is called “<a href="https://researchspace.auckland.ac.nz/">Research Space</a>” and I suspect many of my colleagues might have never heard of it, and many might not know how to make use of it.</p>

<p dir="ltr">Open Access is <a href="http://en.wikipedia.org/wiki/Open_access" target="_blank">usually described</a> as Gold (where the article is made accessible free of charge by the published) or Green (where some version of the manuscript, usually the peer reviewed version, is deposited by the author). I don’t personally find this distinction palatable, because the gold/green definition says more about mechanisms of delivery and less about liberties for reuse.</p>

<p dir="ltr">Those who know me also know that I prefer to think about Free Open Access (where the article is provided free of charge) and Libre Open Access (where the article is provided free of charge and there are few restrictions for reuse and repurposing). The copyright agreements we enter or the licence we choose when publishing open access defines where in the free-libre spectrum the article will sit.</p>

<p dir="ltr">If we wish to communicate our findings as widely as possible, shouldn’t we be opting for libre Open Access, where they can be reused, redistributed and repurposed? This week Daniel Mietchen, Raphael Wimmer and Nils Dagssonwas <a href="http://blogs.plos.org/mindthebrain/2013/10/01/asap-awards-interview-with-daniel-mietchen/">received an award </a>for the work they did taking multimedia files that were part of libre Open Access literature and giving them a new life in WikiMedia, where they can be used to illustrate Wikipedia articles, used for educational purposes, etc.</p>

<p dir="ltr">Unfortunately, research publications do not solely serve the purpose of communicating our findings. They are also perhaps the most important contribution through which our worth as academics will be measured when we apply for a job, apply for promotion or seek to be granted tenure. We may be forgiven a lot by staffing committees, but never a poor publication record. We have been taught that how we brand our publications (where we publish them) will be a major factor for that assessment.</p>

<p dir="ltr">It is not surprising then, that most of us will feel the need to do our best to place our article in the better branded journals, many of which will charge hefty Open Access fees, but will publish our article sometimes at a lower price or free of charge if we are willing to give our rights as authors away to them. Because this decision of where to publish is so intricately tied to career progress, the cultural inertia is hard to overcome.</p>

<p dir="ltr">These days, it is rare that I will find someone who doesn’t think that Open Access is “a good thing” (progress!). As soon as the term “Open Access” enters the discussion, however, I can see the $ shaped tears rolling down someone’s cheeks. Most frequently the discussion veers towards a standard list of “buts”.</p>

<p dir="ltr">Many of these “buts” are myths that seem to persist even in the face of evidence against them. Once they have the mindset that Open Access is not a “viable” alternative to be embraced by them, their immediate community of practice or even their institution, it does not seem to matter how much data is presented -- the response will inevitably be “Oh, ok. [pause] but…” If we cannot change scientists’ minds when confronting them with evidence, how will we be able to persuade our agencies and institutions? Until we overcome our apprehensions about open access, should we just stick to the status quo?</p>

<p dir="ltr">Institutional repositories provide a place where authors that choose to publish in the traditional way can deposit the peer-reviewed accepted article for anyone to access free of charge. All authors need to do is to contact their librarian and they will happily show them how to do this. In New Zealand, articles that are deposited in these repositories are given a second life, free of pay-walls and indexed by Google. In New Zealand the articles (and other research artifacts) are aggregated in <a href="http://nzresearch.org.nz/">http://nzresearch.org.nz/</a>.</p>

<p dir="ltr">There are several types of artifact types listed in nzreasearch (theses, conference posters, journal articles, patents, datasets, etc) and the site provides a really nice user interface to search for material. I could find at the time of writing 20,450 thesis listed, 15,132 research articles and 235 conference posters, for example. I doubt that these numbers (other than theses, perhaps) reflect the actual number of outputs from the NZ research sector. These numbers may instead indicate that more work needs to be done to encourage authors to make the deposition of their outputs in the repository a regular part of their workflow. I can’t help wondering whether, if we were asked to identify at our annual performance review, continuation, or promotions the proportion of our output that was deposited, we might see some progress.</p>

<p dir="ltr">My personal position is that research outputs that result from public funds should be made available under a copyright licence that minimises the restrictions on distribution and re-use. I also understand that authors may base their choice over where they publish on different kinds of reasons (some which I understand and other which I don’t). But even when authors choose to publish under traditional pay-walled schemes, the value of depositing in the institutional repository far outweigh the reasons not to do so.</p>

<p dir="ltr">This year’s Open Access Week focus is on “impact”, and for our outputs to have impact they first need to be read. <a href="https://twitter.com/brembs">Björn</a> Brems put it best when <a href="http://twitter.com/brembs/status/354486926562181120">he said</a>:</p>

<p dir="ltr">"No matter what field (or planet): limiting potential readership does not increase actual readership.”</p>

<p dir="ltr">[1] Definition from <a href="http://www.merriam-webster.com/dictionary/repository">Merriam Webster</a> online dictionary</p>

<p dir="ltr">[You can read more from Fabiana at her blog, <a href="http://sciblogs.co.nz/building-blogs-of-science/" target="_blank">Building Blogs of Science</a>, part of the <a href="http://sciblogs.co.nz/bloggers/" target="_blank">Science Media Centre’s SciBlogs network</a>. She also blogs for the <a href="http://blogs.plos.org/mindthebrain/" target="_blank">Public Library of Science</a>.]</p>

<p></p>
</div>
        </div>
                        <a href="posts/need-libre-open-access.html#disqus_thread" data-disqus-identifier="cache/posts/need-libre-open-access.html">Comments</a>


        </article><article class="teaser h-entry post-text"><h1 class="p-name">
<a href="posts/2013/10/23/open-access-megajournals-have-they-changed-everything.html" class="u-url">Open Access MegaJournals – Have They Changed Everything?</a>
             <time class="published dt-published" datetime="2013-10-23T15:58:57+13:00">2013-10-23 15:58</time>
</h1>
        <div class="e-content">
        <div>
<p></p>
<h5>By Peter Binfield, co-founder of <a href="https://peerj.com)" target="_blank">PeerJ</a> and previously the Publisher of PLOS ONE.</h5>
<p><em>This post follows a talk at the University of British Columbia, which can be recorded and <a href="http://mediasitemob1.mediagroup.ubc.ca/Mediasite/Play/2cdc95b2d56a4c56a6606a6c116a58b01d" target="_blank">can be viewed here</a>. The slides for the talk, synched with the audio of the talk, is <a href="http://www.slideshare.net/PBinfield/oa-mega-journals-ubc-open-event" target="_blank">available on Slideshare</a>. The original dataset for this article, alongside the graphs and the slides, <a href="http://figshare.com/articles/MegaJournal_Publication_Data/833828" target="_blank">can be found at Figshare</a></em>.</p>
<p>‘MegaJournals’ are a reasonably recent phenomena in the history of scholarly publishing, however their popularity (as evidenced by the number of articles they publish) as well as their continuing growth (in title launches, and total output) are creating a new class of journal which has the potential to dramatically change the publishing landscape. This post, which is based on themes that I developed at the <a href="http://oaweek.open.ubc.ca/" target="_blank">UBC Open meeting</a> earlier this week, explores this phenomena and its potential for change.</p>
<p>A ‘megajournal’ is widely understood to be an online-only open access journal, that covers a very broad subject area and selects content based only on scientific and methodological soundness (or some variation on that statement), with a business model which allows each article to cover its own costs. With these attributes, megajournals are not limited in their potential output and as such are able to grow commensurate with any growth in submissions.</p>
<p>It is worth spending a little bit of time on the editorial criteria that these journals are applying. To be explicitly clear, these journals perform extremely rigorous peer-review (and several go so far as to publish the peer review process that each article went through). They do not, however, use notions of ‘impact’ to inform their decision to publish. They critically, and formally, peer-review articles to determine whether or not they deserve to join the scientific literature; they then allow the readership to make their own decisions about the interest level (to them) of any given article once it is published.</p>
<p>To put it another way, they make their publication decisions only on the basis of whether or not a submission deserves to join the scholarly literature. They believe that this approach puts science into the world more rapidly, more efficiently, and more transparently than the ‘traditional’ process of rejecting otherwise publishable work in an attempt to filter articles into specific journal titles. The result is a net benefit to academia.</p>
<p>PLOS ONE is the most visible success story in this category of journal. PLOS ONE is currently expected to publish more than 30,000 articles in 2013, approaching 3% of all STM articles published that year (PubMed indexes approximately 1 million new articles each year). Recognizing the success of this model, many other Publishing Companies and Academic Societies (such as Nature, Springer, SAGE, BioONE, PeerJ, BMJ, F1000, the American Institute of Physics, the American Society of Microbiology, the Genetics Society of America and so on) have launched similar journals and each of them are seeing their megajournals grow in volume, month on month (see the end of this post for a list of all known ‘megajournals’). Because of the size and the growth of titles like PLOS ONE (a growth which is shown in the graph below), much of the attention around the megajournal story has focused on these large broad scope titles.</p>
<p><a href="http://creativecommons.org.nz/wp-content/uploads/2013/10/All-MegaJournal-Output.png"><img class=" wp-image-4752   " alt="The monthly volume of published articles for (a) PLOS ONE (in red) and (b) PLOS ONE + all other extant megajournals (in blue), starting with the launch of PLOS ONE (Dec 2006)" src="http://creativecommons.org.nz/wp-content/uploads/2013/10/All-MegaJournal-Output.png" width="492" height="407"></a> The monthly volume of published articles for (a) PLOS ONE (in red) and (b) PLOS ONE + all other extant megajournals (in blue), starting with the launch of PLOS ONE (Dec 2006)</p>
<p>Normally ‘mega’ is taken to mean ‘million’ and so ‘megajournal’ is clearly somewhat of a misnomer, even for PLOS ONE! Nonetheless, the term has stuck because of the sheer size of the most successful megajournals (titles which aim to publish across an extremely wide subject area).</p>
<p>However, if we put aside the issue of size, then there is another attribute of this type of journal which is important to consider – that of the editorial criteria that is applied. Megajournals such as PLOS ONE, Scientific Reports, BMJ Open, PeerJ and so on peer-review for scientific validity, but they do not pre-judge articles based on subjective notions of ‘impact’, ‘reach’, or ‘degree of advance.’ This editorial criteroa is <b>also </b>being applied by journals in much smaller, or more ‘niche’, subject areas. Clearly, a niche journal (for example, “<a href="http://www.frontiersin.org/neurorobotics" target="_blank">Frontiers in Neurorobotics</a>”) that uses this editorial criteria would not expect to become extremely large (i.e. ‘mega’) due to the fact that it is in a somewhat small field.</p>
<p>Therefore, if we define this ‘class’ of journal as being based on the editorial criteria outlined above, then it is clear that both megajournals and many smaller ‘niche’ journals share the same class. The essential difference between them is simply whether or not they pre-judge the readership of their articles. A truly large megajournal does not need to do that (e.g. anything in the whole of biology, or the whole of medicine, or the whole of science is in scope), but one of the ‘smaller’ journals could reject an otherwise publishable article because it doesn’t fit their more limited subject-area scope (for example, the Frontiers in Neurorobotics journal would not publish a neuroeconomics article).</p>
<p>All of this is a long-winded way of saying that perhaps the term ‘megajournal’ (which refers to the potential size of the journal and only applies to the broad scope titles) is not the best one to help us understand the ‘megajournal’ phenomena. Another way to think about it is to look at the editorial criteria which is applied, regardless of the size (or scope) of the journal. If ‘megajournal’ is a misnomer in many respects, then what would be a better (yet still succinct and understandable) term? Some have suggested ‘non-selective’, or ‘impact neutral’, or ‘rigorous but inclusive review’ but none of these really capture the phenomena. Perhaps that is the topic for an OA Week Competition, or the comments area of this blog post…</p>
<p>When the definition of this journal class is expanded in this way, then it is clear that there are very large programs of journals which apply an editorial criteria similar to that of PLOS ONE – for example, the whole of the “Frontiers In…” series of journals, all of the BMC Series journals (which make up approximately half of the output of BioMed Central), as well as and titles making up approximately 1/3 of the output of Hindawi. To be fair, this point has been made in the past (e.g. by Matt Cockerill and Paul Peters at the <a href="http://river-valley.tv/conferences/coasp-2011" target="_blank">COASP meeting in 2011</a>), but it is my belief that most people’s attention has been focused on PLOS ONE, and similar ‘broad scope’ launches such as Scientific Reports, BMJ Open or PeerJ, with the result that the simultaneous rise of many other ‘impact neutral’ journals has perhaps been overlooked.</p>
<p>Regardless of name, or type, another defining characteristic of these journals is the fact that almost without fail, all journals using this editorial model grow in output, month on month. The overall effect is that the output of the entire class of journals is growing extremely rapidly, and in fact much more significantly than might have been assumed if you simply look at the PLOS ONE output. An illustrative graph is shown below, using data which was compiled with the input of most of the publishers of each of the titles listed in the appendix to this post.</p>
<p><a href="http://creativecommons.org.nz/wp-content/uploads/2013/10/Annual-Article-Output-of-all-impact-neutral-Journals.png"><img class="size-full wp-image-4754 " alt="Annual Article Output of all 'impact neutral' Journals" src="http://creativecommons.org.nz/wp-content/uploads/2013/10/Annual-Article-Output-of-all-impact-neutral-Journals.png" width="628" height="393"></a> The annual volume of published articles published per year for (a) PLOS ONE (in red), and (b) PLOS ONE + all other extant ‘MegaJournals’ (in green), and (c) all journals practicing an ‘impact neutral’ form of peer review (purple), starting with the launch of the BMC Series (in 2000).</p>
<p>So this class of journal is clearly very successful and rapidly growing. In 2012 alone, as can be seen from the graph, approximately 47,000 articles were published using this editorial model, and by extrapolation 2013 could see as many as 75,000 articles published in a model which intentionally makes no ‘pre-publication’ judgments of their significance / impact / degree of advance etc. (note: 75,000 articles is approximately 8% of all STM journal output). And this growth is being driven by a genuine author desire – each of these growing publications have clearly been able to fill a previously unmet need for their authors to the extent that they are flocking to the model, and reporting extremely positive experiences.</p>
<h5><b>But Have They ‘Changed Everything’?</b></h5>

<p>The fact that a journal does not use ‘significance’, ‘impact’, or ‘degree of advance’ to determine whether an article should be published does not mean that those aspects are not important (it is simply that they aren’t important to the decision to publish). If subjective filtering (on whatever criteria) has not happened ‘pre-publication’ for as much as 8% of the academic corpus, then clearly the community needs to apply new tools ‘post publication’ to try to provide these types of signals based on the reception of the article in the real world. To take this a step further, it is also becoming apparent that these journals are changing the way that people think about articles themselves - increasingly, people are coming to understand that the article itself is more important than the journal in which it happens to be published.</p>
<p>This is one of the key reasons, I believe, that we are currently seeing such an explosion in interest in ‘altmetrics’ and why this field is becoming more mainstream. For example, at a recent PLOS-sponsored <a href="http://article-level-metrics.plos.org/alm-workshop-2013/" target="_blank">ALM meeting</a>, representatives from publishers such as Elsevier and Springer, Universities such as Harvard and funders such as Wellcome Trust and Sloan were present. In recent years, we have also seen the creation of article-level metrics programs at many publishers (for example PLOS, and Frontiers), as well as the formation of several start-up companies in the ‘alt-metric’ space such as <a href="http://impactstory.org/" target="_blank">Impact Story</a>, <a href="http://www.altmetric.com/" target="_blank">Altmetric</a>, and <a href="http://www.plumanalytics.com/" target="_blank">Plum Analytics</a>.</p>
<p>Another way in which these journals are causing changes in the publishing world is their ability to publish negative results, or replication studies. Historically, it has been very hard to get studies of this nature published; however, if they had been published, then the community would not need to waste time repeating the mistakes that others had made before (but not made public). These journals are ideal venues for this kind of material. As more and more articles of this type are published, the net benefit to the academic community will be great and much time and energy will be saved.</p>
<p>But perhaps most importantly, as implied at the start of this post, the existence of these journals contributes to a considerable net increase in the speed and efficiency of the overall publishing ecosystem. Traditionally an article might be sent to a ‘first choice’ journal and even if it were publishable it could be rejected based on reasons such as ‘lack of interest’ or ‘insufficient advance in the field’ or ‘lack of novelty‘. That article will have spent weeks or months being peer reviewed, and once rejected it will simply be sent by the authors to their ‘second choice’ journal, where it will again spend weeks or months in the process, and be evaluated again by new peer reviewers (for examples, see <a href="http://grigoriefflab.janelia.org/rejections" target="_blank">this collection of ‘serial rejections</a>’).</p>
<p>Eventually the article will be published (unless the authors give up in despair, which many do), but in the intervening time it will have been delayed by months or years, and it will have wasted the time of multiple reviewers and editors. And all of this time and energy will have been spent in the name of ‘filtering’ the article into a specific journal ‘bucket’. It has been estimated by <a href="http://blog.rubriq.com/2013/06/03/how-we-found-15-million-hours-of-lost-time/" target="_blank">Rubriq</a> that as many as 15 million hours a year are wasted on ‘redundant review’.</p>
<p>By contrast, if an article is peer-reviewed once in a megajournal model, and then (dependent on suitable revisions) it is published, then that article will have entered the public sphere much more rapidly and without wasting the time of additional ‘redundant’ reviewers. If all articles were published in this model then the net benefit to academia (due to increased speed to publication, and reduced duplication of effort by reviewers to name just two effects) would be dramatic.</p>
<p>As Open Access itself grows in importance, we can expect to see more journals of this type launched; however, it is apparent that the growth of this model cannot continue indefinitely. If PLOS ONE already publishes 3% (and growing) of the STM literature, then it does not take many journals (or programs of journals) publishing at that scale before a <b>significant</b> proportion of the scholarly literature is being published in this way with all the advantages that this entails. Put simply, as more and more content is published using this kind of editorial model, then the net result will be that:</p>
<ul>
<li>New business models, new innovations and new thinking are able to flourish in a new publication ecosystem;</li>

    <li>‘Mistakes’ or ‘non-results’(so called ‘negative results’) are actually reported, saving future researchers time, energy, and resources;</li>

    <li>Previously ‘uninteresting’ results can now be reported, providing the potential to incrementally build on these ‘micro findings’;</li>

    <li>Reporting standards can be more easily standardized and the levels more easily raised;</li>

    <li>Less time is wasted by multiple reviewers on the same content;</li>

    <li>The process of publication is made more transparent and fair for the author;</li>

    <li>Better methods of filtering, evaluating and sorting publications will evolve; and finally,</li>

    <li>Science will be published more rapidly, saving author time and improving the overall speed of discovery.</li>

</ul>
<p>And when that happens, then I think it is fair to say that the rise of this editorial model will have changed everything…</p>
<h5><b>Appendix</b></h5>

<p><b>MegaJournals Launched To Date: </b></p>
<p>AIP Advances - 973 articles – launched 2011</p>
<p>Biology Open (the Company of Biologists) – 252 articles – launched 2012</p>
<p>BMJ Open – 1,540 articles – launched 2011</p>
<p>CMAJ Open (Canadian Medical Association) – 15 articles – launched 2013</p>
<p>Cureus – 57 articles – launched 2012</p>
<p>Ecosphere (the Ecological Society of America) – 399 articles – launched 2010</p>
<p>EPJ-Plus (part of the European Physics Journal) – unknown articles - launched 2011</p>
<p>F1000 Research – 225 indexed articles – launched 2012</p>
<p>FEBS Open Bio (Federation of European Biochemical Societies) – 129 articles – launched 2011</p>
<p>G3 (the Genetics Society of America) – 383 articles – launched 2011</p>
<p>mBio (the American Society of Microbiology) – 601 articles – launched 2010</p>
<p>Optics Express (the Optical Society of America) - unknown articles - launched 1997 in some form</p>
<p>PeerJ – 171 articles – launched 2013</p>
<p>PLOS ONE – 75,382 articles – launched 2006</p>
<p>QScience Connect – 53 articles – launched 2011</p>
<p>SAGE Open – 371 articles – launched 2011</p>
<p>SAGE Open Medicine – 12 articles – launched 2013</p>
<p>Scientific Reports (Nature) – 2,731 articles – launched 2011</p>
<p>Springer Plus – 548 articles – launched 2012</p>
<p>The Scientific World Journal (Hindawi) – 1,860 articles – (re)launched 2012</p>
<p><b>Megajournals ‘Coming Soon’:</b></p>
<p>BMJ Open Respiratory Research - 2013</p>
<p>BMJ Open Diabetes Research &amp; Care - 2013</p>
<p>Open Heart (BMJ) - 2013</p>
<p>Elementa (BioONE) - 2013</p>
<p>IEEE Access - 2013</p>
<p>OpenLibHums - 2014</p>
<p>The Cogent Series (T&amp;F) - 2014</p>
<p>The Winnower<b> </b>- 2014</p>
<p><b>Existing large programs of ‘niche’ journals which apply the same editorial criteria (with output through end-2012):</b></p>
<p>The BMC Series of journals (approx. half of the annual output of BMC) – 56,000 articles</p>
<p>The“Frontiers in...” Series (part of Nature Publishing Group) – 9,921</p>
<p>Hindawi: the ISRN series; the "Case Reports in Medicine" series; the "Conference Papers in Science" series; the "Dataset Papers in Science" journal, and the "Scientifica" journal – 6,713 articles</p>
<p><b>Acknowledgements </b>– I would like to acknowledge the input and help of most of the publishers of the journals listed above, as well as Michael Habib of Scopus, for providing publication data and other ‘food for thought’.</p>
</div>
        </div>
                        <a href="posts/2013/10/23/open-access-megajournals-have-they-changed-everything.html#disqus_thread" data-disqus-identifier="cache/posts/2013/10/23/open-access-megajournals-have-they-changed-everything.html">Comments</a>


        </article><article class="teaser h-entry post-text"><h1 class="p-name">
<a href="posts/open-access-megajournals-changed-everything.html" class="u-url">Open Access Megajournals</a>
             <time class="published dt-published" datetime="2013-10-23T00:34:26+13:00">2013-10-23 00:34</time>
</h1>
        <div class="e-content">
        <div>
<p></p>
<h5>By Peter Binfield, co-founder of <a href="https://peerj.com)" target="_blank">PeerJ</a> and previously the Publisher of PLOS ONE.</h5>
<p><em>This post follows a talk at the University of British Columbia, which can be recorded and <a href="http://mediasitemob1.mediagroup.ubc.ca/Mediasite/Play/2cdc95b2d56a4c56a6606a6c116a58b01d" target="_blank">can be viewed here</a>. The slides for the talk, synched with the audio of the talk, is <a href="http://www.slideshare.net/PBinfield/oa-mega-journals-ubc-open-event" target="_blank">available on Slideshare</a>. The original dataset for this article, alongside the graphs and the slides, <a href="http://figshare.com/articles/MegaJournal_Publication_Data/833828" target="_blank">can be found at Figshare</a></em>.</p>
<p>‘MegaJournals’ are a reasonably recent phenomena in the history of scholarly publishing, however their popularity (as evidenced by the number of articles they publish) as well as their continuing growth (in title launches, and total output) are creating a new class of journal which has the potential to dramatically change the publishing landscape. This post, which is based on themes that I developed at the <a href="http://oaweek.open.ubc.ca/" target="_blank">UBC Open meeting</a> earlier this week, explores this phenomena and its potential for change.</p>
<p>A ‘megajournal’ is widely understood to be an online-only open access journal, that covers a very broad subject area and selects content based only on scientific and methodological soundness (or some variation on that statement), with a business model which allows each article to cover its own costs. With these attributes, megajournals are not limited in their potential output and as such are able to grow commensurate with any growth in submissions.</p>
<p>It is worth spending a little bit of time on the editorial criteria that these journals are applying. To be explicitly clear, these journals perform extremely rigorous peer-review (and several go so far as to publish the peer review process that each article went through). They do not, however, use notions of ‘impact’ to inform their decision to publish. They critically, and formally, peer-review articles to determine whether or not they deserve to join the scientific literature; they then allow the readership to make their own decisions about the interest level (to them) of any given article once it is published.</p>
<p>To put it another way, they make their publication decisions only on the basis of whether or not a submission deserves to join the scholarly literature. They believe that this approach puts science into the world more rapidly, more efficiently, and more transparently than the ‘traditional’ process of rejecting otherwise publishable work in an attempt to filter articles into specific journal titles. The result is a net benefit to academia.</p>
<p>PLOS ONE is the most visible success story in this category of journal. PLOS ONE is currently expected to publish more than 30,000 articles in 2013, approaching 3% of all STM articles published that year (PubMed indexes approximately 1 million new articles each year). Recognizing the success of this model, many other Publishing Companies and Academic Societies (such as Nature, Springer, SAGE, BioONE, PeerJ, BMJ, F1000, the American Institute of Physics, the American Society of Microbiology, the Genetics Society of America and so on) have launched similar journals and each of them are seeing their megajournals grow in volume, month on month (see the end of this post for a list of all known ‘megajournals’). Because of the size and the growth of titles like PLOS ONE (a growth which is shown in the graph below), much of the attention around the megajournal story has focused on these large broad scope titles.</p>
<p>Normally ‘mega’ is taken to mean ‘million’ and so ‘megajournal’ is clearly somewhat of a misnomer, even for PLOS ONE! Nonetheless, the term has stuck because of the sheer size of the most successful megajournals (titles which aim to publish across an extremely wide subject area).</p>
<p>However, if we put aside the issue of size, then there is another attribute of this type of journal which is important to consider – that of the editorial criteria that is applied. Megajournals such as PLOS ONE, Scientific Reports, BMJ Open, PeerJ and so on peer-review for scientific validity, but they do not pre-judge articles based on subjective notions of ‘impact’, ‘reach’, or ‘degree of advance.’ This editorial criteroa is <b>also </b>being applied by journals in much smaller, or more ‘niche’, subject areas. Clearly, a niche journal (for example, “<a href="http://www.frontiersin.org/neurorobotics" target="_blank">Frontiers in Neurorobotics</a>”) that uses this editorial criteria would not expect to become extremely large (i.e. ‘mega’) due to the fact that it is in a somewhat small field.</p>
<p>Therefore, if we define this ‘class’ of journal as being based on the editorial criteria outlined above, then it is clear that both megajournals and many smaller ‘niche’ journals share the same class. The essential difference between them is simply whether or not they pre-judge the readership of their articles. A truly large megajournal does not need to do that (e.g. anything in the whole of biology, or the whole of medicine, or the whole of science is in scope), but one of the ‘smaller’ journals could reject an otherwise publishable article because it doesn’t fit their more limited subject-area scope (for example, the Frontiers in Neurorobotics journal would not publish a neuroeconomics article).</p>
<p>All of this is a long-winded way of saying that perhaps the term ‘megajournal’ (which refers to the potential size of the journal and only applies to the broad scope titles) is not the best one to help us understand the ‘megajournal’ phenomena. Another way to think about it is to look at the editorial criteria which is applied, regardless of the size (or scope) of the journal. If ‘megajournal’ is a misnomer in many respects, then what would be a better (yet still succinct and understandable) term? Some have suggested ‘non-selective’, or ‘impact neutral’, or ‘rigorous but inclusive review’ but none of these really capture the phenomena. Perhaps that is the topic for an OA Week Competition, or the comments area of this blog post…</p>
<p>When the definition of this journal class is expanded in this way, then it is clear that there are very large programs of journals which apply an editorial criteria similar to that of PLOS ONE – for example, the whole of the “Frontiers In…” series of journals, all of the BMC Series journals (which make up approximately half of the output of BioMed Central), as well as and titles making up approximately 1/3 of the output of Hindawi. To be fair, this point has been made in the past (e.g. by Matt Cockerill and Paul Peters at the <a href="http://river-valley.tv/conferences/coasp-2011" target="_blank">COASP meeting in 2011</a>), but it is my belief that most people’s attention has been focused on PLOS ONE, and similar ‘broad scope’ launches such as Scientific Reports, BMJ Open or PeerJ, with the result that the simultaneous rise of many other ‘impact neutral’ journals has perhaps been overlooked.</p>
<p>Regardless of name, or type, another defining characteristic of these journals is the fact that almost without fail, all journals using this editorial model grow in output, month on month. The overall effect is that the output of the entire class of journals is growing extremely rapidly, and in fact much more significantly than might have been assumed if you simply look at the PLOS ONE output. An illustrative graph is shown below, using data which was compiled with the input of most of the publishers of each of the titles listed in the appendix to this post.</p>
<p>So this class of journal is clearly very successful and rapidly growing. In 2012 alone, as can be seen from the graph, approximately 47,000 articles were published using this editorial model, and by extrapolation 2013 could see as many as 75,000 articles published in a model which intentionally makes no ‘pre-publication’ judgments of their significance / impact / degree of advance etc. (note: 75,000 articles is approximately 8% of all STM journal output). And this growth is being driven by a genuine author desire – each of these growing publications have clearly been able to fill a previously unmet need for their authors to the extent that they are flocking to the model, and reporting extremely positive experiences.</p>
<h5><b>But Have They ‘Changed Everything’?</b></h5>

<p>The fact that a journal does not use ‘significance’, ‘impact’, or ‘degree of advance’ to determine whether an article should be published does not mean that those aspects are not important (it is simply that they aren’t important to the decision to publish). If subjective filtering (on whatever criteria) has not happened ‘pre-publication’ for as much as 8% of the academic corpus, then clearly the community needs to apply new tools ‘post publication’ to try to provide these types of signals based on the reception of the article in the real world. To take this a step further, it is also becoming apparent that these journals are changing the way that people think about articles themselves - increasingly, people are coming to understand that the article itself is more important than the journal in which it happens to be published.</p>
<p>This is one of the key reasons, I believe, that we are currently seeing such an explosion in interest in ‘altmetrics’ and why this field is becoming more mainstream. For example, at a recent PLOS-sponsored <a href="http://article-level-metrics.plos.org/alm-workshop-2013/" target="_blank">ALM meeting</a>, representatives from publishers such as Elsevier and Springer, Universities such as Harvard and funders such as Wellcome Trust and Sloan were present. In recent years, we have also seen the creation of article-level metrics programs at many publishers (for example PLOS, and Frontiers), as well as the formation of several start-up companies in the ‘alt-metric’ space such as <a href="http://impactstory.org/" target="_blank">Impact Story</a>, <a href="http://www.altmetric.com/" target="_blank">Altmetric</a>, and <a href="http://www.plumanalytics.com/" target="_blank">Plum Analytics</a>.</p>
<p>Another way in which these journals are causing changes in the publishing world is their ability to publish negative results, or replication studies. Historically, it has been very hard to get studies of this nature published; however, if they had been published, then the community would not need to waste time repeating the mistakes that others had made before (but not made public). These journals are ideal venues for this kind of material. As more and more articles of this type are published, the net benefit to the academic community will be great and much time and energy will be saved.</p>
<p>But perhaps most importantly, as implied at the start of this post, the existence of these journals contributes to a considerable net increase in the speed and efficiency of the overall publishing ecosystem. Traditionally an article might be sent to a ‘first choice’ journal and even if it were publishable it could be rejected based on reasons such as ‘lack of interest’ or ‘insufficient advance in the field’ or ‘lack of novelty‘. That article will have spent weeks or months being peer reviewed, and once rejected it will simply be sent by the authors to their ‘second choice’ journal, where it will again spend weeks or months in the process, and be evaluated again by new peer reviewers (for examples, see <a href="http://grigoriefflab.janelia.org/rejections" target="_blank">this collection of ‘serial rejections</a>’).</p>
<p>Eventually the article will be published (unless the authors give up in despair, which many do), but in the intervening time it will have been delayed by months or years, and it will have wasted the time of multiple reviewers and editors. And all of this time and energy will have been spent in the name of ‘filtering’ the article into a specific journal ‘bucket’. It has been estimated by <a href="http://blog.rubriq.com/2013/06/03/how-we-found-15-million-hours-of-lost-time/" target="_blank">Rubriq</a> that as many as 15 million hours a year are wasted on ‘redundant review’.</p>
<p>By contrast, if an article is peer-reviewed once in a megajournal model, and then (dependent on suitable revisions) it is published, then that article will have entered the public sphere much more rapidly and without wasting the time of additional ‘redundant’ reviewers. If all articles were published in this model then the net benefit to academia (due to increased speed to publication, and reduced duplication of effort by reviewers to name just two effects) would be dramatic.</p>
<p>As Open Access itself grows in importance, we can expect to see more journals of this type launched; however, it is apparent that the growth of this model cannot continue indefinitely. If PLOS ONE already publishes 3% (and growing) of the STM literature, then it does not take many journals (or programs of journals) publishing at that scale before a <b>significant</b> proportion of the scholarly literature is being published in this way with all the advantages that this entails. Put simply, as more and more content is published using this kind of editorial model, then the net result will be that:</p>
<ul>
<li>New business models, new innovations and new thinking are able to flourish in a new publication ecosystem;</li>

    <li>‘Mistakes’ or ‘non-results’(so called ‘negative results’) are actually reported, saving future researchers time, energy, and resources;</li>

    <li>Previously ‘uninteresting’ results can now be reported, providing the potential to incrementally build on these ‘micro findings’;</li>

    <li>Reporting standards can be more easily standardized and the levels more easily raised;</li>

    <li>Less time is wasted by multiple reviewers on the same content;</li>

    <li>The process of publication is made more transparent and fair for the author;</li>

    <li>Better methods of filtering, evaluating and sorting publications will evolve; and finally,</li>

    <li>Science will be published more rapidly, saving author time and improving the overall speed of discovery.</li>

</ul>
<p>And when that happens, then I think it is fair to say that the rise of this editorial model will have changed everything…</p>
<h5><b>Appendix</b></h5>

<p><b>MegaJournals Launched To Date: </b></p>
<p>AIP Advances - 973 articles – launched 2011</p>
<p>Biology Open (the Company of Biologists) – 252 articles – launched 2012</p>
<p>BMJ Open – 1,540 articles – launched 2011</p>
<p>CMAJ Open (Canadian Medical Association) – 15 articles – launched 2013</p>
<p>Cureus – 57 articles – launched 2012</p>
<p>Ecosphere (the Ecological Society of America) – 399 articles – launched 2010</p>
<p>EPJ-Plus (part of the European Physics Journal) – unknown articles - launched 2011</p>
<p>F1000 Research – 225 indexed articles – launched 2012</p>
<p>FEBS Open Bio (Federation of European Biochemical Societies) – 129 articles – launched 2011</p>
<p>G3 (the Genetics Society of America) – 383 articles – launched 2011</p>
<p>mBio (the American Society of Microbiology) – 601 articles – launched 2010</p>
<p>Optics Express (the Optical Society of America) - unknown articles - launched 1997 in some form</p>
<p>PeerJ – 171 articles – launched 2013</p>
<p>PLOS ONE – 75,382 articles – launched 2006</p>
<p>QScience Connect – 53 articles – launched 2011</p>
<p>SAGE Open – 371 articles – launched 2011</p>
<p>SAGE Open Medicine – 12 articles – launched 2013</p>
<p>Scientific Reports (Nature) – 2,731 articles – launched 2011</p>
<p>Springer Plus – 548 articles – launched 2012</p>
<p>The Scientific World Journal (Hindawi) – 1,860 articles – (re)launched 2012</p>
<p><b>Megajournals ‘Coming Soon’:</b></p>
<p>BMJ Open Respiratory Research - 2013</p>
<p>BMJ Open Diabetes Research &amp; Care - 2013</p>
<p>Open Heart (BMJ) - 2013</p>
<p>Elementa (BioONE) - 2013</p>
<p>IEEE Access - 2013</p>
<p>OpenLibHums - 2014</p>
<p>The Cogent Series (T&amp;F) - 2014</p>
<p>The Winnower<b> </b>- 2014</p>
<p><b>Existing large programs of ‘niche’ journals which apply the same editorial criteria (with output through end-2012):</b></p>
<p>The BMC Series of journals (approx. half of the annual output of BMC) – 56,000 articles</p>
<p>The“Frontiers in...” Series (part of Nature Publishing Group) – 9,921</p>
<p>Hindawi: the ISRN series; the "Case Reports in Medicine" series; the "Conference Papers in Science" series; the "Dataset Papers in Science" journal, and the "Scientifica" journal – 6,713 articles</p>
<p><b>Acknowledgements </b>– I would like to acknowledge the input and help of most of the publishers of the journals listed above, as well as Michael Habib of Scopus, for providing publication data and other ‘food for thought’.</p>
</div>
        </div>
                        <a href="posts/open-access-megajournals-changed-everything.html#disqus_thread" data-disqus-identifier="cache/posts/open-access-megajournals-changed-everything.html">Comments</a>


        </article><article class="teaser h-entry post-text"><h1 class="p-name">
<a href="posts/2013/10/22/levelling-up-to-open-research-data.html" class="u-url">Levelling up to Open Research Data</a>
             <time class="published dt-published" datetime="2013-10-22T17:53:28+13:00">2013-10-22 17:53</time>
</h1>
        <div class="e-content">
        <div>
<p></p>
<strong>By Deborah Fitchett, Digital Access Coordinator at Lincoln University.
<p></p></strong>
<p>The movement to open up research data is gaining momentum. Both publishers and funders are starting to require researchers to publish their data at the same time as the results and conclusions they've derived from it. Most recently, the <a href="http://www.msi.govt.nz/assets/Update-me/National-Science-Challenges/Request-for-proposals/RfP-1st-tranche-Oct-2013.pdf">National Science Challenges' Request for Proposals (pdf)</a> requires fundees to explain how they will comply with the <a href="http://ict.govt.nz/guidance-and-resources/information-and-data/nzgoal/">New Zealand Government Open Access and Licensing Framework</a> and provide for access to and re-use of data generated (p.13).</p>
<p><strong>Publishing data</strong></p>
<p>Because publication of research data is still relatively new, it looks complicated and scary. And it can be complicated if you want it to be. A really large project might make it worth creating its own website to host the resulting dataset(s) and present them in a custom set of interfaces. [quote float="right"]Every dataset you publish, no matter how small or incomplete or imperfect, is a wheel someone else doesn't have to reinvent<a href="posts/2013/10/22/The%20National%20Science%20Challenges%20let%20you%20apply%20funding%20to%20provide%20for%20access%20to%20and%20re-use%20of%20data.">/quote</a> Look at <a href="http://geonet.org.nz/">GeoNet</a> (on the off-chance you haven't already!) for an example: it provides raw data from the quake drums, and both initial and confirmed calculations about the size and location of quakes. Data is presented pre-digested on maps for the casual visitor, and in <a href="http://info.geonet.org.nz/display/appdata/Earthquake+Web+Feature+Service">open data formats</a> for the more sophisticated reuser.</p>
<p>But publication can also be as easy as spending a minute creating a <a href="http://figshare.com/">figShare</a> account and another minute uploading your file and adding a title and subject keywords. Click a button and your data has a permanent home and DOI.</p>
<p>Perhaps midway are subject-specific repositories (over 600 listed on <a href="http://www.re3data.org/">re3data</a> alone): these tend to have more metadata/documentation requirements or other forms of quality control. <a href="http://datadryad.com/">Dryad</a> has recently instigated a small data publishing charge. A number of journals are paying this charge for their authors: perhaps for the good of science, perhaps recognising that the <a href="https://peerj.com/articles/175/">data publication citation advantage</a> is good for their impact factors.</p>
<p><strong>Open data</strong></p>
<p>Publishing is a good start, but it's not the same as making the data open for reuse. Peter Desmet's <a href="http://peterdesmet.com/posts/illegal-bullfrogs.html">illegal bullfrogs</a> demonstrates how we lose out when data reuse is restricted, whether by intent or neglect.</p>
<p>Fortuitously a lot of data publication venues support or require published data to be open data. FigShare and Dryad for example both require a <a href="http://creativecommons.org/about/cc0">Creative Commons Zero</a> licence. This lets people use the data in any application without even the need for attribution -- useful if their application pulls together data from dozens, hundreds, or thousands of sources.</p>
<p>It's important to note that this doesn't affect the scholarly norm of citing your sources, any more than the expiration of copyright means you no longer need to cite Aristotle, Murasaki, or Marie Curie. <a href="http://www.datacite.org/">DataCite</a>, among many others, is working on data citation standards, but the main principle is that data should be cited just as articles and books are.</p>
<p><strong>Better data</strong></p>
<p>So publishing data is easy, and publishing data openly is easy. Publishing open data <em>well</em> is the hard thing -- just as it is for any human skill or endeavour. You start with the basics and level up according to your capacity and needs. The <a href="https://certificates.theodi.org/">ODI Open Data Certification process</a> is a friendly way both to recognise what level you're at and to let you know what direction you can develop in next.</p>
<p>You might, for example, start by publishing in a proprietary format like Excel, then later level up to publishing in the open CSV format, or machine-readable XML, or a chart with the data embedded behind it using a tool like <a href="http://blog.martinfenner.org/2013/07/19/creating-charts-with-datawrapper/">Datawrapper</a>, or a bundle of formats for different uses plus interactive visualisations.</p>
<p>Your first time, you might realise you don't have consent from your human participants to publish their data, so limit yourself to publishing only the data gathered by other means -- then on your next research project you might plan for data publication right from the ethics approval stage.</p>
<p><strong>Planning for data</strong></p>
<p>The words "Data Management Plan" strike fear in the researcher's heart, conjuring up the spectre of voluminous forms full of bureacratese and technical specifications. But all it means is to ask yourself:</p>
<ul>
<li>what data you intend to gather;</li>

    <li>how you'll analyse and document it;</li>

    <li>what ethical questions it raises and how you'll deal with those;</li>

    <li>how you'll store it safely and securely while you're carrying out your research;</li>

    <li>and what you'll do with it afterwards -- whether to publish all or part of it, archive it privately for a period, or in some cases destroy it.</li>

</ul>
<p>The UK's Digital Curation Centre's <a href="http://www.dcc.ac.uk/sites/default/files/documents/resource/DMP-checklist-post-consultation-v2.pdf">2009 checklist for a data management plan (pdf)</a> consisted of over 80 questions - but <a href="http://www.dcc.ac.uk/sites/default/files/documents/resource/DMP_Checklist_2013.pdf">its most recent version (pdf)</a> has only 24 (or <a href="http://www.dcc.ac.uk/node/10020">just 13, depending how you count</a>). The idea is simply to make sure you've thought about these things before beginning your project, so you don't get caught by surprise when the journal you submit to at the end of it requires you to publish your data.</p>
<p><strong>Perfect data</strong></p>
<p>There's no such thing.</p>
<p><strong>The best data</strong></p>
<p>Ranganathan's <a href="https://en.wikipedia.org/wiki/Five_laws_of_library_science">Five Laws of Library Science</a> could easily be reapplied here, beginning: Data is for use.</p>
<p>The best data is the data that someone finds when they need it. They might have to convert it or tidy it or reanalyse it -- but if they have the data they can do all these things.</p>
<p>If you can thoroughly document your data, do; but if not, don't let that stop you putting your data up. If you can convert it into an open machine-readable format, do; but if not, don't let that be why it languishes on your hard drive. If you can publish all your data under a Creative Commons Zero licence, do; but if not, publish some of it, under whatever licence you can.</p>
<p>Every dataset you publish, no matter how small or incomplete or imperfect, is a wheel someone else doesn't have to reinvent. Start small, but start; and keep the wheels of science turning.</p>
</div>
        </div>
                        <a href="posts/2013/10/22/levelling-up-to-open-research-data.html#disqus_thread" data-disqus-identifier="cache/posts/2013/10/22/levelling-up-to-open-research-data.html">Comments</a>


        </article><article class="teaser h-entry post-text"><h1 class="p-name">
<a href="posts/levelling-open-research-data.html" class="u-url">Levelling Up to Open Research Data</a>
             <time class="published dt-published" datetime="2013-10-22T00:37:06+13:00">2013-10-22 00:37</time>
</h1>
        <div class="e-content">
        <div>
<p></p>
<strong>By Deborah Fitchett, Digital Access Coordinator at Lincoln University.
<p></p></strong>
<p>The movement to open up research data is gaining momentum. Both publishers and funders are starting to require researchers to publish their data at the same time as the results and conclusions they've derived from it. Most recently, the <a href="http://www.msi.govt.nz/assets/Update-me/National-Science-Challenges/Request-for-proposals/RfP-1st-tranche-Oct-2013.pdf">National Science Challenges' Request for Proposals (pdf)</a> requires fundees to explain how they will comply with the <a href="http://ict.govt.nz/guidance-and-resources/information-and-data/nzgoal/">New Zealand Government Open Access and Licensing Framework</a> and provide for access to and re-use of data generated (p.13).</p>
<p><strong>Publishing data</strong></p>
<p>Because publication of research data is still relatively new, it looks complicated and scary. And it can be complicated if you want it to be. A really large project might make it worth creating its own website to host the resulting dataset(s) and present them in a custom set of interfaces. (The National Science Challenges let you apply funding to provide for access to and re-use of data.) Look at <a href="http://geonet.org.nz/">GeoNet</a> (on the off-chance you haven't already!) for an example: it provides raw data from the quake drums, and both initial and confirmed calculations about the size and location of quakes. Data is presented pre-digested on maps for the casual visitor, and in <a href="http://info.geonet.org.nz/display/appdata/Earthquake+Web+Feature+Service">open data formats</a> for the more sophisticated reuser.</p>
<p>But publication can also be as easy as spending a minute creating a <a href="http://figshare.com/">figShare</a> account and another minute uploading your file and adding a title and subject keywords. Click a button and your data has a permanent home and DOI.</p>
<p>Perhaps midway are subject-specific repositories (over 600 listed on <a href="http://www.re3data.org/">re3data</a> alone): these tend to have more metadata/documentation requirements or other forms of quality control. <a href="http://datadryad.com/">Dryad</a> has recently instigated a small data publishing charge. A number of journals are paying this charge for their authors: perhaps for the good of science, perhaps recognising that the <a href="https://peerj.com/articles/175/">data publication citation advantage</a> is good for their impact factors.</p>
<p><strong>Open data</strong></p>
<p>Publishing is a good start, but it's not the same as making the data open for reuse. Peter Desmet's <a href="http://peterdesmet.com/posts/illegal-bullfrogs.html">illegal bullfrogs</a> demonstrates how we lose out when data reuse is restricted, whether by intent or neglect.</p>
<p>Fortuitously a lot of data publication venues support or require published data to be open data. FigShare and Dryad for example both require a <a href="http://creativecommons.org/about/cc0">Creative Commons Zero</a> licence. This lets people use the data in any application without even the need for attribution -- useful if their application pulls together data from dozens, hundreds, or thousands of sources.</p>
<p>It's important to note that this doesn't affect the scholarly norm of citing your sources, any more than the expiration of copyright means you no longer need to cite Aristotle, Murasaki, or Marie Curie. <a href="http://www.datacite.org/">DataCite</a>, among many others, is working on data citation standards, but the main principle is that data should be cited just as articles and books are.</p>
<p><strong>Better data</strong></p>
<p>So publishing data is easy, and publishing data openly is easy. Publishing open data <em>well</em> is the hard thing -- just as it is for any human skill or endeavour. You start with the basics and level up according to your capacity and needs. The <a href="https://certificates.theodi.org/">ODI Open Data Certification process</a> is a friendly way both to recognise what level you're at and to let you know what direction you can develop in next.</p>
<p>You might, for example, start by publishing in a proprietary format like Excel, then later level up to publishing in the open CSV format, or machine-readable XML, or a chart with the data embedded behind it using a tool like <a href="http://blog.martinfenner.org/2013/07/19/creating-charts-with-datawrapper/">Datawrapper</a>, or a bundle of formats for different uses plus interactive visualisations.</p>
<p>Your first time, you might realise you don't have consent from your human participants to publish their data, so limit yourself to publishing only the data gathered by other means -- then on your next research project you might plan for data publication right from the ethics approval stage.</p>
<p><strong>Planning for data</strong></p>
<p>The words "Data Management Plan" strike fear in the researcher's heart, conjuring up the spectre of voluminous forms full of bureacratese and technical specifications. But all it means is to ask yourself:</p>
<ul>
<li>what data you intend to gather;</li>

    <li>how you'll analyse and document it;</li>

    <li>what ethical questions it raises and how you'll deal with those;</li>

    <li>how you'll store it safely and securely while you're carrying out your research;</li>

    <li>and what you'll do with it afterwards -- whether to publish all or part of it, archive it privately for a period, or in some cases destroy it.</li>

</ul>
<p>The UK's Digital Curation Centre's <a href="http://www.dcc.ac.uk/sites/default/files/documents/resource/DMP-checklist-post-consultation-v2.pdf">2009 checklist for a data management plan (pdf)</a> consisted of over 80 questions - but <a href="http://www.dcc.ac.uk/sites/default/files/documents/resource/DMP_Checklist_2013.pdf">its most recent version (pdf)</a> has only 24 (or <a href="http://www.dcc.ac.uk/node/10020">just 13, depending how you count</a>). The idea is simply to make sure you've thought about these things before beginning your project, so you don't get caught by surprise when the journal you submit to at the end of it requires you to publish your data.</p>
<p><strong>Perfect data</strong></p>
<p>There's no such thing.</p>
<p><strong>The best data</strong></p>
<p>Ranganathan's <a href="https://en.wikipedia.org/wiki/Five_laws_of_library_science">Five Laws of Library Science</a> could easily be reapplied here, beginning: Data is for use.</p>
<p>The best data is the data that someone finds when they need it. They might have to convert it or tidy it or reanalyse it -- but if they have the data they can do all these things.</p>
<p>If you can thoroughly document your data, do; but if not, don't let that stop you putting your data up. If you can convert it into an open machine-readable format, do; but if not, don't let that be why it languishes on your hard drive. If you can publish all your data under a Creative Commons Zero licence, do; but if not, publish some of it, under whatever licence you can.</p>
<p>Every dataset you publish, no matter how small or incomplete or imperfect, is a wheel someone else doesn't have to reinvent. Start small, but start; and keep the wheels of science turning.</p>
</div>
        </div>
                        <a href="posts/levelling-open-research-data.html#disqus_thread" data-disqus-identifier="cache/posts/levelling-open-research-data.html">Comments</a>


        </article><article class="teaser h-entry post-text"><h1 class="p-name">
<a href="posts/2013/10/21/a-big-year-oa-in-australia-2013.html" class="u-url">A Big Year - OA in Australia 2013</a>
             <time class="published dt-published" datetime="2013-10-21T17:04:34+13:00">2013-10-21 17:04</time>
</h1>
        <div class="e-content">
        <div>
<p></p>
<div>
<div>

<h5>By Dr Danny Kingsley<a href="http://creativecommons.org.nz/wp-content/uploads/2013/10/120x240.jpg"><img class="alignright size-full wp-image-4722" alt="120x240" src="http://creativecommons.org.nz/wp-content/uploads/2013/10/120x240.jpg" width="120" height="240"></a>
</h5>

This has been a big year for open access around the world, and developments in Australia have moved apace.



Two things happened on the first of January 2013 – the Australian Research Council (ARC) announced their <a href="http://www.arc.gov.au/applicants/open_access.htm" target="_blank">open access policy</a> and the <a href="http://aoasg.org.au" target="_blank">Australian Open Access Support Group</a> (AOASG) began operations (disclaimer – I work as the Executive Officer for the AOASG).

<h5>Funding policies</h5>

The ARC policy is very similar to the <a href="http://www.nhmrc.gov.au/grants/policy/dissemination-research-findings" target="_blank">policy</a> introduced on 1 July 2012 by the Australia’s other government funding body – the National Health and Medical Research Council (NHMRC). <a href="http://aoasg.org.au/resources/comparison-of-arc-nhmrc-policies/" target="_blank">Both policies require</a> that the Chief Investigators for funded projects should add metadata about their publications to their institutional repositories at the time of acceptance. There should be a link to the open access version within 12 months of publication. Neither policy advocates a particular method of achieving open access, and both policies specifically do not require payment for open access. However both organisations allow use of grant funding to pay for publication.



[quote float="left"]This Open Access Week... has shaped up to be the largest yet. Every state and territory is hosting events.[/quote]



These policies stand out because they specifically look to use the established infrastructure in Australia. All Australian universities, (and many other institutions) have <a href="http://aoasg.org.au/open-access-repositories-at-australian-institutions/." target="_blank">established an institutional repository</a>  Generally to date Australia has enjoyed strong <a href="http://aoasg.org.au/2013/03/19/centrally-supported-open-access-initiatives-in-australia/" target="_blank">commitment and support from the government</a> to develop infrastructure for open access.



At an Open Access Week event organised by the AOASG, the CEOs of both the ARC and the NHMRC <a href="https://www.youtube.com/watch?v=2Kcj8j3LyBQ" target="_blank">spoke about these policies.</a> They noted that given the speed of change in scholarly communication it is almost impossible to know what the open access agenda will look like in five years time. For this reason neither the NHMRC nor the ARC wish to be prescriptive about how to implement their policies. They did note that while there are no current plans to withhold future grants from researchers that do not comply with the policies, this could become the case into the future.

<h5>Events and activities</h5>

That was one of many <a href="http://aoasg.org.au/oawk-events-2013/" target="_blank">OAWk events</a> being held in Australia in 2013, which has shaped up to be the largest yet. Every state and territory is hosting events with more than half the country’s universities participating.



The week following OAWk will see a large open access-themed conference – the <a href="http://www.oar2013.qut.edu.au" target="_blank">Open Access and Research Conference</a> held at QUT from 30 October to 1 November. This event will feature many high-profile international speakers.



Earlier in 2013 the <a href="http://www.humanities.org.au/About/AlliedOrganisations/NationalScholarlyCommunicationsForum.aspx" target="_blank">National Scholarly Communication Forum</a> was held, addressing the topic “Open Access Research Issues in the Humanities and Social Sciences”. A full run down of the presentations, themes and readings is <a href="http://aoasg.org.au/2013/05/16/notes-from-the-national-scholarly-communication-forum-may-3-2013/" target="_blank">here</a>.

<h5>Informing the discussion</h5>

Throughout the year the AOASG has worked towards its goal of informing and encouraging the discussion around open access. The primary output of the group has been the development of the AOASG webpage. This consists of a combination of information about open access specific to Australia, links to useful resources, and discussion points about events in the open access space both in Australia and overseas.



The site has had over 26,000 visitors since going live in February. An analysis of page statistics indicates a strong interest in practitioner issues. The most popular blog has been “<a href="http://aoasg.org.au/2013/04/10/so-you-want-people-to-read-your-thesis/" target="_blank">So you want people to read your thesis?</a>”, followed by “<a href="http://aoasg.org.au/2013/03/25/journal-editors-take-note-you-have-the-power/" target="_blank">Journal editors take note – you have the power</a>". The most popular webpage (apart from the homepage) is the <a href="http://aoasg.org.au/open-access-in-action/australian-oa-journals/" target="_blank">list of Australian OA journals</a>. The website also contains several graphics including <a href="http://aoasg.org.au/how-to-make-research-oa/" target="_blank">posters</a> and <a href="http://aoasg.org.au/resources/policy-compliance-decision-tree/" target="_blank">flowcharts</a> that are available for download under CC-BY license.



The Australian and New Zealand repository community has been fortunate to have a strong community of practice which developed over several years through discussion lists and community days organised through the CAUL Australasian Institutional Repository Support Service (CAIRSS). While CAIRSS no longer exists, the Council of Australian University Librarians (<a href="http://www.caul.edu.au" target="_blank">CAUL</a>) has continued to support these important services.



[quote float="right"]The AOASG began with representatives from six universities with open access policies. During the year more have been announced.[/quote]



To complement this community, AOASG started the <a href="http://mailman.anu.edu.au/mailman/listinfo/australian_oa_community" target="_blank">Australian Open Access Community Discussion List</a> which pleasingly has had a strong uptake. Over 200 people have joined the list, representing a wide range of backgrounds. While 72% of the members are library-associated, a significant number of these are from research institutions outside the university sector. We have a positive interest from researchers, with many joining the list. There has also been some international interest – with members from India, Japan and Singapore plus several from New Zealand.



Twitter has been a very useful way to share the vast amount of developments, publications, policies and resources that are part of the open access area. The Twitter feed @openaccess_oz has sent over 1,200 notifications during the year. Followers come from all over the world.



Possibly the most positive sign for open access in Australia is the increasing number of policies in institutions. The AOASG began with representatives from six universities with open access policies. During the year more have been announced and it is anticipated that others are intending to during or around OAWk. There is a full list of Australian OA policies <a href="http://aoasg.org.au/resources/" target="_blank">here</a>. The AOASG is looking to expand its membership for 2014, which is shaping to be an even bigger year for open access in Australia.



</div>

</div>

<p><em>[box style="rounded" border="full"]Dr Danny Kingsley is the Executive Officer for the <a href="posts/2013/10/21/wwww.aoasg.org.au" target="_blank">Australian Open Access Support Group</a>. Follow AOASG on Twitter: @openaccess_oz; to get in touch, <a href="http://aoasg.org.au/contact-us/" target="_blank">visit their homepage</a>. [/box] 'A Big Year - OA in Australia 2013' by Dr Danny Kingsley is made available under a <a href="http://creativecommons.org/licenses/by/3.0/" target="_blank">Creative Commons Attribution 3.0 Unported licence</a>. </em></p>
<p>[The <a href="http://www.openaccessweek.org/page/downloads-2" target="_blank">Open Access Week Banner</a> is made available under a <a href="http://creativecommons.org/licenses/by/2.0/" target="_blank">Creative Commons Attribution 2.0 Unported licence</a>.]</p>
</div>
        </div>
                        <a href="posts/2013/10/21/a-big-year-oa-in-australia-2013.html#disqus_thread" data-disqus-identifier="cache/posts/2013/10/21/a-big-year-oa-in-australia-2013.html">Comments</a>


        </article><article class="teaser h-entry post-text"><h1 class="p-name">
<a href="posts/2013/10/21/open-access-week.html" class="u-url">Welcome to Open Access Week 2013!</a>
             <time class="published dt-published" datetime="2013-10-21T11:54:19+13:00">2013-10-21 11:54</time>
</h1>
        <div class="e-content">
        <div>
<p></p>
<p style="text-align:center;"><a href="http://creativecommons.org.nz/wp-content/uploads/2013/10/header_865x180.jpg"><img class="wp-image-4707 aligncenter" alt="header_865x180" src="http://creativecommons.org.nz/wp-content/uploads/2013/10/header_865x180.jpg" width="623" height="130"></a></p>
<p>Welcome to Open Access Week 2013! For the next seven days, researchers, librarians and members of the public around the world are holding lectures, debates and public gatherings to discuss the global move to open up scholarly research.</p>
<p>By 'open', we mean free of all legal and technical restrictions on access and reuse, for everyone. At present, much of the world's scholarly output is both prohibitively expensive and locked away under 'All Rights Reserved' copyright.  The good news is that change is coming: in the last eighteen months, we've  seen a slew of mandates and policies -- from both funding bodies and research institutions -- insisting that publicly funded research be made publicly available.</p>
<p>Keeping track of these policies can be difficult. OA is still relatively new, and we are seeing funders and research institutions take a range of different approaches to OA; OA has, in turn, produced its own idiosyncratic vocabulary. Is it Green? Or Gold? Or some other colour altogether? How about libre? Or gratis? Post-print or pre-print? Is there an embargo? And what is this 'Creative Commons' I keep hearing so much about?</p>
<p><a href="http://creativecommons.org.nz/wp-content/uploads/2013/10/oa_blue_orange02large.gif"><img class=" wp-image-4709 " alt="oa_blue_orange02large" src="http://creativecommons.org.nz/wp-content/uploads/2013/10/oa_blue_orange02large.gif" width="190" height="209"></a> <a href="http://blogs.library.auckland.ac.nz/research-support/archive/2013/10/08/Open-Access-Week-21---27-October-2013.aspx" target="_blank">Kiwi Open Access Logo </a>by the University of Auckland, Libraries and Learning Services is licensed under a <a href="posts/2013/10/21/Creative%20Commons%20Attribution%203.0%20Unported%20License." target="_blank">Creative Commons Attribution 3.0 Unported License.</a></p>
<p>And so, it should come as no surprise that, as these policies are drafted and implemented, there has been be a great deal of debate.</p>
<p>On the one hand, some argue that OA fails to take into account the economics of publishing high quality scholarly research, and that smaller publishers simply will not survive a world where research is free and open. On the other hand, some point to the success of new publishing models -- like PLOS And PeerJ -- and argue that the basic principal of open access and licensing for publicly funded research, coupled with the potential of the internet to disseminate information, is simply too great to ignore.</p>
<p>There are, of course, between and beyond these simple poles, many other points of view. While Creative Commons Aotearoa New Zealand takes the latter position -- our mission, after all, is <a href="http://creativecommons.org/about" target="_blank">to realise the full potential of the Internet</a> -- our own community is very broad, with community members taking a range of differing positions. We understand, as a result, that the transition to OA will not be simple or easy, and that we will need a wide-ranging and open debate as the transition to OA proceeds.</p>
<p>This is where <a href="http://www.openaccessweek.org/" target="_blank">Open Access Week</a> comes in. Now in its sixth year, OA Week aims to "connect the global momentum toward open sharing with the advancement of policy changes on the local level." With that in mind, New Zealand has taken its place as a small but significant part of this global discussion. Last year, <a href="http://creativecommons.org.nz/2012/10/open-access-in-aotearoa-oa-week-2012/" target="_blank">researchers and librarians around the country organised OA Week events</a>, and this year is no different.</p>
<p>Auckland University is holding a range of public events (including <a href="http://blogs.library.auckland.ac.nz/engineering/archive/2013/10/17/Open-Access-WeekAgain.aspx" target="_blank">a talk from Creative Commons Aotearoa New Zealand</a>, 2pm Tuesday). Lincoln University – which recently became New Zealand's first open access university – is also holding <a href="http://library.lincoln.ac.nz/About/News/Current-news/Open-Access-Week-21-27-Oct/" target="_blank">a series of events</a>, including a discussion of researchers' experiences with OA.</p>
<p>Australia, too, is holding a series of OA Week events – at least one in every Australia state. Their <a href="http://aoasg.org.au/oawk-events-2013/" target="_blank">Open Access Support Group</a> has more information about what's happening in Australia.</p>
<p>And what about Creative Commons Aotearoa New Zealand? First of all, we've made an A5 resource, Open Access in Aotearoa, to introduce people to the basic concepts of open access to scholarly research, which you can find on our <a href="http://creativecommons.org.nz/research/" target="_blank">Research homepage</a>.</p>
<p>We're also doing our bit by repeating a scaled-down version of last year's <a href="http://creativecommons.org.nz/category/oa-week-2012/" target="_blank">Open Access Week blog posts.</a> For the entire week, we're hosting blog posts by a range of publishers, technologists, librarians and researchers, sharing their thoughts on everything from peer review to open data. Watch this space for more information over the days ahead!</p>
<p>[The <a href="http://www.openaccessweek.org/page/downloads-2" target="_blank">Open Access Week Banner</a> is made available under a <a href="http://creativecommons.org/licenses/by/2.0/" target="_blank">Creative Commons Attribution 2.0 Unported licence.]</a></p>
</div>
        </div>
                        <a href="posts/2013/10/21/open-access-week.html#disqus_thread" data-disqus-identifier="cache/posts/2013/10/21/open-access-week.html">Comments</a>


        </article><div>
        <ul class="pager">
<li class="previous">
                <a href="index-20.html" rel="prev">← Newer posts</a>
            </li>
            <li class="next">
                <a href="index-18.html" rel="next">Older posts →</a>
            </li>
        </ul>
</div>

                   <script>var disqus_shortname="nikolademo";(function(){var a=document.createElement("script");a.async=true;a.src="//"+disqus_shortname+".disqus.com/count.js";(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(a)}());</script>
</div>
                </div>
                <div id="ftr">
                </div>
            </div>
        </div>
    </div>
	<footer><small>Contents © 2015         <a href="mailto:matt@creativecommons.org.nz">CCANZ</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         
<a rel="license" href="https://creativecommons.org/licenses/by/4.0/">
<img alt="Creative Commons License BY" style="border-width:0; margin-bottom:12px;" src="https://upload.wikimedia.org/wikipedia/commons/1/16/CC-BY_icon.svg"></a>
</small><p>Except where otherwise noted, copyright content on this site is licensed under a Creative Commons Attribution 4.0 International Licence.</p>

	</footer>
</body>
</html>
